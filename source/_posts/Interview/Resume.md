---
title: Resume
date: 2020-09-08 02:46:04
categories: Interview
tags:
---

### Wei Feng
♦ beyondfengwei@gmail.com ♦ (412)-520-5875 ♦ linkedin: https://www.linkedin.com/in/wei-feng-3730ba10b/
#### Education
**Carnegie Mellon University**
• Master of Electrical Computer Engineering May 2017 | Pittsburgh PA
• Course: Cloud Computing, Data Structure and Algorithm, How to Write Fast Code, Computer Architecture
**Nanjing University of Posts and Communications**
• Bachelor of Computer Science and Technology June 2015 | Nanjing China 
• Course: C / C++, Java, Web Application, Computer System, Computer Network, Software Engineering
#### Experience
**Senior Software Engineer | Bloomberg LP (Full Stack)              4/2018 - now**
**Workflow Project**
• Create new workflow from Bloomberg UI to Comdb2 Database
• Split the Serial Workflow into Parallel Workflow with batch request to improve the performance.
• Design and Discuss Request Schema and Internal API for new feature cross teams 
**Distributed Cache Project**
• Add Distributed Chipmunk cache layer in SET infrastructure
• Design integration test cases for distributed cache system
• Deploy cache in 26 product machines, for each machine. 63 million traffic one day
average QPS is 730 r/s, maximum QPS is 7000 r/s, total cache size 3.2G, maximum one key value size 25M , average is 100K.
**Automatic Test Project**
• Design the new Algorithm for pricing platform response analysis
• Use Python to implement the new algorithm to compare two different results from development and
production machines.
• Build the automatic test tool to improve the performance and save time for test

**Software Engineer | Pinterest (Full Stack) 05/2017- 04/2018**
**Crawler System Project**
• Add feature for Pinterest Crawler System ( Aragog ) to solve web robot rules problem
• Use Python to scraped Ads information from the Google and Bing and upload to Hive table
• Build the Jupyter report for Pinterest sales team with python Pandas Dataframe
**Keyword Generator Project**
• Create daily, weekly, monthly workflow for keyword information for keyword generator
• Use Hive , Cascading etl sequence file from hive to Hfile, upload to key value system ( Terrapin ) 
• Add the normalization and stem feature for interest to keyword pipeline, optimize the job
**Real Time Spark Workflow**
• Create ads long click counts workflow in Ads Serving Real Time Stats System
• Implement a Spark job with Scala transfer the data from Kafka to S3
• Join Accuracy is 97.63 % for 10 min, 99.99 % for 24 hours
#### Skills
• Coding Language: Java, C++/C, Python, PHP, SQL, Linux Shell, JavaScript, HTML, Go, Matlab
• Tools: MySQL, MongoDB, Hbase, Sqlite3, Hadoop, Spring, ThinkPHP.OpenMP, CUDA,Hive
